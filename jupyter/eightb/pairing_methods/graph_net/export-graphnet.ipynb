{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef215b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import git\n",
    "\n",
    "import uproot as ut\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import math\n",
    "import vector\n",
    "import sympy as sp\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "import torch\n",
    "\n",
    "sys.path.append( git.Repo('.', search_parent_directories=True).working_tree_dir )\n",
    "from utils import *\n",
    "\n",
    "import utils.torchUtils as gnn\n",
    "\n",
    "plt.style.use('science')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.rcParams['font.size'] =  15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339cf0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(fc.passthrough.TESTING_MX_700_MY_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b5370ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.argmax(tree.n_jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8cf317c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = gnn.Dataset('data/signal-testing',transform=gnn.to_uptri_graph)\n",
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a63e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import Linear, GCNConv\n",
    "from utils.torchUtils.layers import EdgeConv, EdgeConvONNX\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,nn1_out=32,nn2_out=64,for_onnx=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        EdgeConvLayer = EdgeConv\n",
    "        if for_onnx: EdgeConvLayer = EdgeConvONNX\n",
    "        \n",
    "        nn1 = torch.nn.Sequential(\n",
    "            Linear(2*testing.num_node_features +\n",
    "                   testing.num_edge_features, nn1_out),\n",
    "            torch.nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.conv1 = EdgeConvLayer(nn1, edge_aggr=None, return_with_edges=True)\n",
    "\n",
    "        nn2 = torch.nn.Sequential(\n",
    "            Linear(5*nn1_out, nn2_out),\n",
    "            torch.nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.conv2 = EdgeConvLayer(nn2, edge_aggr=None, return_with_edges=True)\n",
    "\n",
    "        self.edge_seq = torch.nn.Sequential(\n",
    "            Linear(3*nn2_out, 2),\n",
    "        )\n",
    "\n",
    "        self.node_seq = torch.nn.Sequential(\n",
    "            Linear(nn2_out, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_x):\n",
    "        # x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        \n",
    "        x, edge_x = self.conv1(x, edge_index, edge_x)\n",
    "        x, edge_x = self.conv2(x, edge_index, edge_x)\n",
    "        x, edge_x = self.node_seq(x), self.edge_seq(edge_x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1), F.log_softmax(edge_x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb391fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gnn.GCN.load_from_checkpoint('models/graph_classifier/lightning_logs/version_1/checkpoints/epoch=19-step=31999.ckpt',dataset=testing)\n",
    "# model_for_onnx = gnn.GCN.load_from_checkpoint('models/graph_classifier/lightning_logs/version_1/checkpoints/epoch=19-step=31999.ckpt',dataset=testing,for_onnx=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33404da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "model_for_onnx = GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce3eace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(graph,pad_nodes=None):\n",
    "    node_x = graph.x \n",
    "    edge_index = graph.edge_index \n",
    "    edge_x = graph.edge_attr \n",
    "    \n",
    "    if pad_nodes: \n",
    "        node_x = F.pad(node_x,(0,0,0,pad_nodes-graph.num_nodes))\n",
    "    return (node_x,edge_index,edge_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7af12578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_outputs(outputs_1,outputs_2):\n",
    "    with torch.no_grad():\n",
    "        for out0,out1 in zip(outputs_1,outputs_2):\n",
    "            print(out0.shape,out1.shape)\n",
    "            print( ((out0-out1)**2).sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b72e5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([11, 5]), torch.Size([2, 55]), torch.Size([55, 1])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values = get_inputs(testing[1662])\n",
    "input_names = ['node_x','edge_index','edge_x']\n",
    "output_names = ['node_y','edge_y']\n",
    "list(map(lambda t:t.shape,input_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b394ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 2]) torch.Size([11, 2])\n",
      "tensor(0.0517)\n",
      "torch.Size([55, 2]) torch.Size([55, 2])\n",
      "tensor(0.3866)\n"
     ]
    }
   ],
   "source": [
    "org_output = model(*input_values)\n",
    "new_output = model_for_onnx(*input_values)\n",
    "\n",
    "compare_outputs(org_output,new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e20a3f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7587, -0.6317],\n",
       "         [-0.7718, -0.6202],\n",
       "         [-0.7373, -0.6509],\n",
       "         [-0.7238, -0.6634],\n",
       "         [-0.7542, -0.6356],\n",
       "         [-0.6956, -0.6907],\n",
       "         [-0.6560, -0.7318],\n",
       "         [-0.7134, -0.6733],\n",
       "         [-0.6413, -0.7478],\n",
       "         [-0.6842, -0.7022],\n",
       "         [-0.6464, -0.7422]], grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[-0.7228, -0.6643],\n",
       "         [-0.6952, -0.6911],\n",
       "         [-0.7135, -0.6732],\n",
       "         [-0.7113, -0.6753],\n",
       "         [-0.7158, -0.6710],\n",
       "         [-0.7563, -0.6337],\n",
       "         [-0.7391, -0.6492],\n",
       "         [-0.6819, -0.7045],\n",
       "         [-0.7014, -0.6850],\n",
       "         [-0.6978, -0.6886],\n",
       "         [-0.6889, -0.6974]], grad_fn=<LogSoftmaxBackward>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_output[0],new_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f310dcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed on an operator with unrecognized namespace torch_scatter::scatter_max. If you are trying to export a custom operator, make sure you registered it with the right domain and version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m     param\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=5'>6</a>\u001b[0m     torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(model,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=6'>7</a>\u001b[0m                     input_values,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=7'>8</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mgnn-model.onnx\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=8'>9</a>\u001b[0m                     input_names\u001b[39m=\u001b[39;49minput_names,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=9'>10</a>\u001b[0m                     output_names\u001b[39m=\u001b[39;49moutput_names,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=10'>11</a>\u001b[0m                     opset_version\u001b[39m=\u001b[39;49m\u001b[39m12\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=11'>12</a>\u001b[0m                     dynamic_axes\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=12'>13</a>\u001b[0m                         \u001b[39m'\u001b[39;49m\u001b[39mnode_x\u001b[39;49m\u001b[39m'\u001b[39;49m: {\u001b[39m0\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mn_nodes\u001b[39;49m\u001b[39m'\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=13'>14</a>\u001b[0m                         \u001b[39m'\u001b[39;49m\u001b[39medge_index\u001b[39;49m\u001b[39m'\u001b[39;49m: {\u001b[39m1\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mn_edges\u001b[39;49m\u001b[39m'\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=14'>15</a>\u001b[0m                         \u001b[39m'\u001b[39;49m\u001b[39medge_x\u001b[39;49m\u001b[39m'\u001b[39;49m: {\u001b[39m0\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mn_edges\u001b[39;49m\u001b[39m'\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=15'>16</a>\u001b[0m                         \u001b[39m'\u001b[39;49m\u001b[39mnode_y\u001b[39;49m\u001b[39m'\u001b[39;49m: {\u001b[39m0\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mn_nodes\u001b[39;49m\u001b[39m'\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=16'>17</a>\u001b[0m                         \u001b[39m'\u001b[39;49m\u001b[39medge_y\u001b[39;49m\u001b[39m'\u001b[39;49m: {\u001b[39m0\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mn_edges\u001b[39;49m\u001b[39m'\u001b[39;49m}}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000011vscode-remote?line=17'>18</a>\u001b[0m                     )\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py:275\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=38'>39</a>\u001b[0m \u001b[39mExport a model into ONNX format.  This exporter runs your model\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=39'>40</a>\u001b[0m \u001b[39monce in order to get a trace of its execution to be exported;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=270'>271</a>\u001b[0m \u001b[39m        than ONNX.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=271'>272</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=273'>274</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m--> <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=274'>275</a>\u001b[0m \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39;49mexport(model, args, f, export_params, verbose, training,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=275'>276</a>\u001b[0m                     input_names, output_names, aten, export_raw_ir,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=276'>277</a>\u001b[0m                     operator_export_type, opset_version, _retain_param_name,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=277'>278</a>\u001b[0m                     do_constant_folding, example_outputs,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=278'>279</a>\u001b[0m                     strip_doc_string, dynamic_axes, keep_initializers_as_inputs,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=279'>280</a>\u001b[0m                     custom_opsets, enable_onnx_checker, use_external_data_format)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py:88\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=85'>86</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=86'>87</a>\u001b[0m         operator_export_type \u001b[39m=\u001b[39m OperatorExportTypes\u001b[39m.\u001b[39mONNX\n\u001b[0;32m---> <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=87'>88</a>\u001b[0m _export(model, args, f, export_params, verbose, training, input_names, output_names,\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=88'>89</a>\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type, opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=89'>90</a>\u001b[0m         _retain_param_name\u001b[39m=\u001b[39;49m_retain_param_name, do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=90'>91</a>\u001b[0m         example_outputs\u001b[39m=\u001b[39;49mexample_outputs, strip_doc_string\u001b[39m=\u001b[39;49mstrip_doc_string,\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=91'>92</a>\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes, keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=92'>93</a>\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets, enable_onnx_checker\u001b[39m=\u001b[39;49menable_onnx_checker,\n\u001b[1;32m     <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=93'>94</a>\u001b[0m         use_external_data_format\u001b[39m=\u001b[39;49muse_external_data_format)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py:689\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=684'>685</a>\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=685'>686</a>\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=687'>688</a>\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=688'>689</a>\u001b[0m     _model_to_graph(model, args, verbose, input_names,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=689'>690</a>\u001b[0m                     output_names, operator_export_type,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=690'>691</a>\u001b[0m                     example_outputs, _retain_param_name,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=691'>692</a>\u001b[0m                     val_do_constant_folding,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=692'>693</a>\u001b[0m                     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=693'>694</a>\u001b[0m                     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=694'>695</a>\u001b[0m                     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes)\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=696'>697</a>\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=697'>698</a>\u001b[0m defer_weight_export \u001b[39m=\u001b[39m export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m ExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py:463\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=457'>458</a>\u001b[0m graph, params, torch_out, module \u001b[39m=\u001b[39m _create_jit_graph(model, args,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=458'>459</a>\u001b[0m                                                      _retain_param_name)\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=460'>461</a>\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[0;32m--> <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=462'>463</a>\u001b[0m graph \u001b[39m=\u001b[39m _optimize_graph(graph, operator_export_type,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=463'>464</a>\u001b[0m                         _disable_torch_constant_prop\u001b[39m=\u001b[39;49m_disable_torch_constant_prop,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=464'>465</a>\u001b[0m                         fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size, params_dict\u001b[39m=\u001b[39;49mparams_dict,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=465'>466</a>\u001b[0m                         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes, input_names\u001b[39m=\u001b[39;49minput_names,\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=466'>467</a>\u001b[0m                         module\u001b[39m=\u001b[39;49mmodule)\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=467'>468</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msymbolic_helper\u001b[39;00m \u001b[39mimport\u001b[39;00m _onnx_shape_inference\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=468'>469</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(model, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction):\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py:200\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=197'>198</a>\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m dynamic_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dynamic_axes\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=198'>199</a>\u001b[0m     torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[0;32m--> <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=199'>200</a>\u001b[0m graph \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_jit_pass_onnx(graph, operator_export_type)\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=200'>201</a>\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_jit_pass_lint(graph)\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=202'>203</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msymbolic_helper\u001b[39;00m \u001b[39mimport\u001b[39;00m _export_onnx_opset_version\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py:313\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=310'>311</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_symbolic_function\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=311'>312</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m--> <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/__init__.py?line=312'>313</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39;49m_run_symbolic_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py:1080\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(g, block, n, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=1077'>1078</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m symbolic_fn(g, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattrs)\n\u001b[1;32m   <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=1078'>1079</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=1079'>1080</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mONNX export failed on an operator with unrecognized namespace \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m::\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=1080'>1081</a>\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mIf you are trying to export a custom operator, make sure you registered \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=1081'>1082</a>\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mit with the right domain and version.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ns, op_name))\n\u001b[1;32m   <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=1082'>1083</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/onnx/utils.py?line=1083'>1084</a>\u001b[0m     \u001b[39mif\u001b[39;00m operator_export_type \u001b[39m==\u001b[39m OperatorExportTypes\u001b[39m.\u001b[39mONNX_FALLTHROUGH:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ONNX export failed on an operator with unrecognized namespace torch_scatter::scatter_max. If you are trying to export a custom operator, make sure you registered it with the right domain and version."
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(model,\n",
    "                    input_values,\n",
    "                    \"gnn-model.onnx\",\n",
    "                    input_names=input_names,\n",
    "                    output_names=output_names,\n",
    "                    opset_version=12,\n",
    "                    dynamic_axes={\n",
    "                        'node_x': {0: 'n_nodes'},\n",
    "                        'edge_index': {1: 'n_edges'},\n",
    "                        'edge_x': {0: 'n_edges'},\n",
    "                        'node_y': {0: 'n_nodes'},\n",
    "                        'edge_y': {0: 'n_edges'}}\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70b3b485",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39monnx\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m onnx_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mgnn-model.onnx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnal/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/jet_selection/graph_net/export-graphnet.ipynb#ch0000012vscode-remote?line=2'>3</a>\u001b[0m onnx\u001b[39m.\u001b[39mchecker\u001b[39m.\u001b[39mcheck_model(onnx_model)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnx'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load('gnn-model.onnx')\n",
    "onnx.checker.check_model(onnx_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4366d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_sess = ort.InferenceSession('gnn-model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fec0f1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[7, 5], edge_index=[2, 21], edge_attr=[21, 1], y=[7], edge_y=[21])\n",
      "torch.Size([20, 2]) (20, 2)\n",
      "tensor(0.)\n",
      "torch.Size([21, 2]) (21, 2)\n",
      "tensor(2.4869e-14)\n"
     ]
    }
   ],
   "source": [
    "g = testing[0]\n",
    "print(g)\n",
    "input_values = get_inputs(g,pad_nodes=20)\n",
    "output_values = model(*input_values)\n",
    "onnx_output = ort_sess.run(None,{name:value.numpy() for name,value in zip(input_names,input_values)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90d98bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51562   , 0.48437998],\n",
       "       [0.5112753 , 0.4887247 ],\n",
       "       [0.50532067, 0.4946793 ],\n",
       "       [0.5060546 , 0.49394533],\n",
       "       [0.5042418 , 0.49575827],\n",
       "       [0.5060317 , 0.4939682 ],\n",
       "       [0.4981752 , 0.5018248 ],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998],\n",
       "       [0.51562   , 0.48437998]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(onnx_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0c917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dc50badf6bcf34ee37feb4ddab24eb1b71716d96fc6cae89d10c22f5e3462c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
