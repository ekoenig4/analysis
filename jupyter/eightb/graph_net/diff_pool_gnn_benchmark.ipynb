{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef215b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import git\n",
    "\n",
    "import uproot as ut\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import math\n",
    "import vector\n",
    "import sympy as sp\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "\n",
    "sys.path.append( git.Repo('.', search_parent_directories=True).working_tree_dir )\n",
    "from utils import *\n",
    "\n",
    "import utils.torchUtils as gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11a05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.typing import Adj, PairTensor\n",
    "from typing import Callable, Optional, Union, Tuple\n",
    "from torch.nn import Linear, Module\n",
    "from torch.nn.functional import softmax, relu, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2797b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(n_nodes, device=None):\n",
    "    arange = torch.arange(n_nodes, device=device)\n",
    "    rows = torch.repeat_interleave(arange, n_nodes).to(device=device)\n",
    "    cols = torch.repeat_interleave(arange[None], n_nodes, dim=0).reshape(-1).to(device=device)\n",
    "    return torch.stack([rows,cols]).to(device=device)\n",
    "\n",
    "def batch_fully_connected(n_nodes, batch_size, device=None):\n",
    "    edge_index = fully_connected(n_nodes, device=device)\n",
    "    edge_index = torch.repeat_interleave(edge_index[None], batch_size, dim=0).to(device=device)\n",
    "    edge_index = edge_index + n_nodes*torch.arange(batch_size).reshape(-1,1,1).to(device=device)\n",
    "    rows, cols = edge_index[:,0], edge_index[:,1]\n",
    "    return torch.stack([rows.flatten(), cols.flatten()]).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedd3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def batched_pool(s : Tensor, batch_ptr : Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    n_in, n_out = s.shape\n",
    "    batch_size = batch_ptr.shape[0] - 1\n",
    "    batch_pool = torch.zeros(n_in, n_out*batch_size).to(s.device)\n",
    "    batch_pool_mask = torch.zeros(n_in, n_out*batch_size).to(s.device)\n",
    "    nodes = torch.stack([torch.arange(batch_size),batch_ptr[:-1], batch_ptr[1:]]).to(s.device)\n",
    "    for node in nodes.T:\n",
    "        i, lo, hi = node[0], node[1], node[2]\n",
    "        batch_pool[lo:hi,n_out*i:n_out*(i+1)] = s[lo:hi]\n",
    "        batch_pool_mask[lo:hi,n_out*i:n_out*(i+1)] = 1\n",
    "    return batch_pool, batch_pool_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ee221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def flatten_pool(pool_matrix : Tensor, nclusters : int, batch_ptr : Tensor) -> Tensor:\n",
    "    batch_size = batch_ptr.shape[0] - 1\n",
    "    flat_pool = torch.zeros(batch_ptr[-1], nclusters)\n",
    "    nodes = torch.stack([torch.arange(batch_size),batch_ptr[:-1], batch_ptr[1:]])\n",
    "    for node in nodes.T:\n",
    "        i, lo, hi = node[0], node[1], node[2]\n",
    "        flat_pool[lo:hi] = pool_matrix[lo:hi,nclusters*i:nclusters*(i+1)]\n",
    "    return flat_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c3129fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self, n_in_node, n_in_edge, n_out,  n_out_clusters):\n",
    "        super().__init__()\n",
    "        self.n_in_node = n_in_node\n",
    "        self.n_in_edge = n_in_edge\n",
    "        self.n_out = n_out\n",
    "        self.n_out_clusters = n_out_clusters\n",
    "        \n",
    "        self.norm = gnn.layers.GCNNormalize()\n",
    "        self.node_embeding = torch.nn.Linear(n_in_node, n_out)\n",
    "        self.edge_embeding = torch.nn.Linear(n_in_edge, n_out)\n",
    "        self.adj_embeding = torch.nn.Linear(n_out, 2)\n",
    "        self.pooling = torch.nn.Linear(n_out, n_out_clusters)\n",
    "\n",
    "    def _graph_diff_pool(self, x, adj):\n",
    "        x = self.s.T @ x\n",
    "\n",
    "        adj = adj.movedim(2, 0)\n",
    "        adj = adj @ self.s\n",
    "        adj = self.s.T @ adj\n",
    "        adj = adj.movedim(0, 2)\n",
    "        \n",
    "        edge_index = fully_connected(self.n_out_clusters, x.device)\n",
    "        edge_attr = adj[edge_index[0],edge_index[1]]\n",
    "        return x, edge_index, edge_attr\n",
    "        \n",
    "    def _batch_diff_pool(self, x, adj, batch_ptr):\n",
    "        self.s, self.mask = batched_pool(self.s , batch_ptr)\n",
    "\n",
    "        x = self.s.T @ x\n",
    "\n",
    "        adj = adj.movedim(2, 0)\n",
    "        adj = adj @ self.s\n",
    "        adj = self.s.T @ adj\n",
    "        adj = adj.movedim(0, 2)\n",
    "\n",
    "\n",
    "        edge_index = batch_fully_connected(self.n_out_clusters, batch_ptr.shape[0]-1, x.device)\n",
    "        edge_attr = adj[edge_index[0],edge_index[1]]\n",
    "        return x, edge_index, edge_attr\n",
    "\n",
    "    def _loss(self, adj):\n",
    "        self.link_loss = adj - torch.matmul(self.s, self.s.T)\n",
    "        self.link_loss = torch.norm(self.link_loss, p=2)\n",
    "        self.link_loss = self.link_loss/adj.numel()\n",
    "\n",
    "        self.ent_loss = (-self.s * torch.log(self.s + 1e-15)).sum(dim=-1).mean()\n",
    "\n",
    "    def flatten_pool(self, s):\n",
    "        if self.batch_ptr is None: return s\n",
    "        return flatten_pool(s, self.n_out_clusters, self.batch_ptr)\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj, edge_attr: Tensor, batch_ptr : Optional[Tensor] = None) -> Tensor:\n",
    "        x, edge_attr = self.norm(x, edge_index, edge_attr)\n",
    "\n",
    "        edge_attr = self.edge_embeding(edge_attr)\n",
    "\n",
    "        adj_attr = torch.sparse_coo_tensor(edge_index, edge_attr).to_dense()\n",
    "        adj = softmax(self.adj_embeding(edge_attr), dim=-1)[:,1]\n",
    "        adj = torch.sparse_coo_tensor(edge_index, adj).to_dense()\n",
    "        \n",
    "        x = self.node_embeding( torch.matmul(adj, x) )\n",
    "        self.s = softmax( relu( self.pooling(x) ), dim=-1 )\n",
    "        self.mask = torch.ones_like(self.s)\n",
    "\n",
    "        if batch_ptr is None or True:\n",
    "            x, edge_index, edge_attr = self._graph_diff_pool(x, adj_attr)\n",
    "        else:\n",
    "            x, edge_index, edge_attr = self._batch_diff_pool(x, adj_attr, batch_ptr)\n",
    "        self.batch_ptr = batch_ptr\n",
    "\n",
    "        self._loss(adj)\n",
    "\n",
    "        return x, edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebbf0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoldenModule(Module):\n",
    "    def __init__(self, n_in_node=5, n_in_edge=4, layers=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = gnn.layers.GCNConvMSG(n_in_node=n_in_node, n_in_edge=n_in_edge, n_out=layers)\n",
    "        self.relu1 = gnn.layers.GCNRelu()\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj, edge_attr: Tensor) -> Tensor:\n",
    "        x, edge_attr = self.conv1(x, edge_index, edge_attr)\n",
    "        x, edge_attr = self.relu1(x, edge_index, edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a8070e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from torch.nn.functional import nll_loss, log_softmax\n",
    "from torchmetrics.functional import accuracy, auroc\n",
    "\n",
    "class Model(LightningModule):\n",
    "    def __init__(self,n_in_node=5, n_in_edge=4):\n",
    "        super().__init__()\n",
    "        self.norm = gnn.layers.GCNNormalize()\n",
    "\n",
    "        self.golden1 = GoldenModule(n_in_node=n_in_node, n_in_edge=n_in_edge, layers=32)\n",
    "        self.h_pool = DiffPool(32, 3*32, 16, 5)\n",
    "\n",
    "        self.golden2 = GoldenModule(n_in_node=16, n_in_edge=16, layers=32)\n",
    "        self.y_pool = DiffPool(32, 3*32, 16, 3)\n",
    "\n",
    "        self.golden3 = GoldenModule(n_in_node=16, n_in_edge=16, layers=32)\n",
    "        self.x_pool = DiffPool(32, 3*32, 16, 2)\n",
    "\n",
    "    def forward(self, data : Data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        batch_ptr = data.ptr if hasattr(data, 'ptr') else None\n",
    "\n",
    "        x, edge_attr = self.golden1(x, edge_index, edge_attr)\n",
    "        # x, edge_index, edge_attr = self.h_pool(x, edge_index, edge_attr, batch_ptr)\n",
    "        # batch_ptr = self.h_pool.n_out_clusters*torch.arange(data.num_graphs) if hasattr(data, 'ptr') else None\n",
    "        \n",
    "        # x, edge_attr = self.golden2(x, edge_index, edge_attr)\n",
    "        # x, edge_index, edge_attr = self.y_pool(x, edge_index, edge_attr, batch_ptr)\n",
    "        # batch_ptr = self.y_pool.n_out_clusters*torch.arange(data.num_graphs) if hasattr(data, 'ptr') else None\n",
    "        \n",
    "        x, edge_attr = self.golden3(x, edge_index, edge_attr)\n",
    "        x, edge_index, edge_attr = self.x_pool(x, edge_index, edge_attr, batch_ptr)\n",
    "\n",
    "        # node_h_pool = self.h_pool.s\n",
    "        # node_h_mask = self.h_pool.mask\n",
    "        # node_y_pool = node_h_pool @ self.y_pool.s \n",
    "        # node_y_mask = node_h_mask @ self.y_pool.mask\n",
    "        node_x_pool = self.x_pool.s \n",
    "        node_x_mask = self.x_pool.mask\n",
    "        \n",
    "        return (\n",
    "            # node_h_pool[node_h_mask>0].reshape(-1, self.h_pool.n_out_clusters), \n",
    "            # node_y_pool[node_y_mask>0].reshape(-1, self.y_pool.n_out_clusters), \n",
    "            node_x_pool[node_x_mask>0].reshape(-1, self.x_pool.n_out_clusters), \n",
    "        )\n",
    "\n",
    "    def step(self, batch, batch_idx, tag):\n",
    "        # h_pool, y_pool, x_pool = self(batch)\n",
    "        x_pool, = self(batch)\n",
    "\n",
    "        # h_pool_loss = nll_loss( log_softmax(h_pool), batch.h_pool_tru)/5. # + self.h_pool.link_loss + self.h_pool.ent_loss\n",
    "        # y_pool_loss = nll_loss( log_softmax(y_pool), batch.y_pool_tru)/3. # + self.y_pool.link_loss + self.y_pool.ent_loss\n",
    "        x_pool_loss = nll_loss( log_softmax(x_pool), batch.x_pool_tru)/2. # + self.x_pool.link_loss + self.x_pool.ent_loss\n",
    "\n",
    "        loss = x_pool_loss\n",
    "\n",
    "        # h_auroc = auroc(h_pool[:,1], batch.x_pool_tru)\n",
    "        # self.log(f'{tag}/auroc', h_auroc)\n",
    "\n",
    "\n",
    "        self.log(f'{tag}/loss',loss)\n",
    "        return loss\n",
    "    def training_step(self, batch, batch_idx): return self.step(batch ,batch_idx, 'train')\n",
    "    def validation_step(self, batch, batch_idx): return self.step(batch ,batch_idx, 'valid')\n",
    "    def test_step(self, batch, batch_idx):  return self.step(batch ,batch_idx, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d35b5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, DenseDataLoader\n",
    "\n",
    "def load_dataset(fn='data/MX_1200_MY_500-training', template=None, shuffle=False):\n",
    "    dataset = gnn.Dataset(fn,transform=template.transform)\n",
    "    training, testing = gnn.train_test_split(dataset[:3000], 0.33)\n",
    "    training, validation = gnn.train_test_split(training, 0.5)\n",
    "\n",
    "    batch_size = 1\n",
    "    trainloader = DataLoader(training, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "    validloader = DataLoader(validation, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "    testloader = DataLoader(testing, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "\n",
    "    return trainloader, validloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9232b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pool_weight(pool_tru, nclusters):\n",
    "    n_tot = pool_tru.shape[0]\n",
    "    n_tru = (pool_tru > 0).sum()\n",
    "    n_fak = (pool_tru == 0).sum()\n",
    "\n",
    "    weight = torch.Tensor([n_fak]+[n_tru]*(nclusters-1))\n",
    "    weight = n_tot - weight\n",
    "    return weight\n",
    "\n",
    "\n",
    "class PoolTruth(BaseTransform):\n",
    "    def __call__(self, data : Data) -> Data:\n",
    "        data.h_pool_tru = (data.node_id+1)//2\n",
    "        data.h_pool_weight = get_pool_weight(data.h_pool_tru, 5)\n",
    "\n",
    "        data.y_pool_tru = (data.h_pool_tru+1)//2\n",
    "        data.y_pool_weight = get_pool_weight(data.y_pool_tru, 3)\n",
    "\n",
    "        data.x_pool_tru = (data.y_pool_tru+1)//2\n",
    "        data.x_pool_weight = get_pool_weight(data.x_pool_tru, 2)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5b3ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = gnn.Dataset('data/template',make_template=True, transform=gnn.Transform(PoolTruth()))\n",
    "trainloader, validloader, testloader = load_dataset(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b5799e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9f522f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4844, 0.1289, 0.1289, 0.1289, 0.1289],\n",
       "         [0.6348, 0.0913, 0.0913, 0.0913, 0.0913],\n",
       "         [0.6236, 0.0941, 0.0941, 0.0941, 0.0941],\n",
       "         [0.5667, 0.1083, 0.1083, 0.1083, 0.1083],\n",
       "         [0.7602, 0.0599, 0.0599, 0.0599, 0.0599],\n",
       "         [0.5948, 0.1013, 0.1013, 0.1013, 0.1013],\n",
       "         [0.8289, 0.0428, 0.0428, 0.0428, 0.0428],\n",
       "         [0.3959, 0.1510, 0.1510, 0.1510, 0.1510],\n",
       "         [0.4888, 0.1278, 0.1278, 0.1278, 0.1278]], grad_fn=<ViewBackward>),\n",
       " tensor([[0.6841, 0.1579, 0.1579],\n",
       "         [0.7763, 0.1119, 0.1119],\n",
       "         [0.7694, 0.1153, 0.1153],\n",
       "         [0.7346, 0.1327, 0.1327],\n",
       "         [0.8531, 0.0735, 0.0735],\n",
       "         [0.7518, 0.1241, 0.1241],\n",
       "         [0.8952, 0.0524, 0.0524],\n",
       "         [0.6299, 0.1850, 0.1850],\n",
       "         [0.6868, 0.1566, 0.1566]], grad_fn=<ViewBackward>),\n",
       " tensor([[0.0743, 0.9257],\n",
       "         [0.0526, 0.9474],\n",
       "         [0.0542, 0.9458],\n",
       "         [0.0624, 0.9376],\n",
       "         [0.0345, 0.9655],\n",
       "         [0.0584, 0.9416],\n",
       "         [0.0247, 0.9753],\n",
       "         [0.0870, 0.9130],\n",
       "         [0.0736, 0.9264]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(trainloader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24ef164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | norm    | GCNNormalize | 0     \n",
      "1 | golden1 | GoldenModule | 480   \n",
      "2 | h_pool  | DiffPool     | 2.2 K \n",
      "3 | golden2 | GoldenModule | 1.6 K \n",
      "4 | y_pool  | DiffPool     | 2.2 K \n",
      "5 | golden3 | GoldenModule | 1.6 K \n",
      "6 | x_pool  | DiffPool     | 2.1 K \n",
      "-----------------------------------------\n",
      "10.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 K    Total params\n",
      "0.041     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2009/2009 [01:19<00:00, 25.26it/s, loss=0.294, v_num=73]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(gpus=0, max_epochs=1)\n",
    "trainer.fit(model, trainloader, validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d797a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████▉| 988/991 [00:28<00:00, 37.23it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/loss': 3.3573358058929443}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 991/991 [00:29<00:00, 34.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 3.3573358058929443}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c87d5ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.9570e-01, 1.9570e-01, 2.1720e-01, 1.9570e-01, 1.9570e-01],\n",
       "         [1.9570e-01, 1.9570e-01, 2.1720e-01, 1.9570e-01, 1.9570e-01],\n",
       "         [1.9570e-01, 1.9570e-01, 2.1719e-01, 1.9570e-01, 1.9570e-01],\n",
       "         [1.9572e-01, 1.9572e-01, 2.1711e-01, 1.9572e-01, 1.9572e-01],\n",
       "         [9.9998e-01, 3.9986e-06, 3.9986e-06, 3.9986e-06, 3.9986e-06],\n",
       "         [9.9992e-01, 1.9643e-05, 1.9643e-05, 1.9643e-05, 1.9643e-05],\n",
       "         [9.9999e-01, 2.2264e-06, 2.2264e-06, 2.2264e-06, 2.2264e-06],\n",
       "         [9.9999e-01, 2.2861e-06, 2.2861e-06, 2.2861e-06, 2.2861e-06],\n",
       "         [1.9570e-01, 1.9570e-01, 2.1719e-01, 1.9570e-01, 1.9570e-01]],\n",
       "        grad_fn=<ViewBackward>),\n",
       " tensor([[0.0652, 0.0652, 0.8695],\n",
       "         [0.0652, 0.0652, 0.8695],\n",
       "         [0.0652, 0.0652, 0.8695],\n",
       "         [0.0652, 0.0652, 0.8695],\n",
       "         [0.3333, 0.3333, 0.3333],\n",
       "         [0.3333, 0.3333, 0.3334],\n",
       "         [0.3333, 0.3333, 0.3333],\n",
       "         [0.3333, 0.3333, 0.3333],\n",
       "         [0.0652, 0.0652, 0.8695]], grad_fn=<ViewBackward>),\n",
       " tensor([[0.0000, 1.0000],\n",
       "         [0.0000, 1.0000],\n",
       "         [0.0000, 1.0000],\n",
       "         [0.0000, 1.0000],\n",
       "         [0.0000, 1.0000],\n",
       "         [0.0000, 1.0000],\n",
       "         [0.0000, 1.0000],\n",
       "         [0.0000, 1.0000],\n",
       "         [0.0000, 1.0000]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(testloader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24c867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dc50badf6bcf34ee37feb4ddab24eb1b71716d96fc6cae89d10c22f5e3462c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
