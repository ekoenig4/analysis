{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef215b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import git\n",
    "\n",
    "import uproot as ut\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import math\n",
    "import vector\n",
    "import sympy as sp\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "\n",
    "sys.path.append( git.Repo('.', search_parent_directories=True).working_tree_dir )\n",
    "from utils import *\n",
    "\n",
    "import utils.torchUtils as gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11a05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch_geometric\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.typing import Adj, PairTensor\n",
    "from typing import Callable, Optional, Union, Tuple\n",
    "from torch.nn import Linear, Module\n",
    "from torch.nn.functional import softmax, relu, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cd5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairJets:\n",
    "    def __call__(self, data : Data) -> Data:\n",
    "        uptri_mask = data.edge_index[0] < data.edge_index[1]\n",
    "        dijet_features = torch.nn.functional.pad(data.edge_attr[uptri_mask], (1,0))\n",
    "        dijet_i, dijet_j = data.edge_index[:,uptri_mask]\n",
    "        dijet_y = data.edge_y[uptri_mask]\n",
    "        dijet_id = data.edge_id[uptri_mask]\n",
    "\n",
    "        node_type = data.get('node_type', torch.zeros(data.num_nodes))\n",
    "        data.node_type = torch.cat([node_type, torch.full_like(dijet_i, 1)]).long()\n",
    "       \n",
    "        data.x = torch.cat([data.x,dijet_features])\n",
    "        data.y = torch.cat([data.y, dijet_y])\n",
    "        data.node_id = torch.cat([data.node_id, dijet_id])\n",
    "\n",
    "        dijet_idx = torch.where(data.node_type == 1)[0]\n",
    "        data.edge_index = torch.stack([torch.cat([dijet_i, dijet_idx, dijet_j, dijet_idx]), torch.cat([dijet_idx, dijet_j, dijet_idx, dijet_i])])\n",
    "        data.edge_attr = torch.ones_like(data.edge_index[0]).reshape(-1, 1)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c848286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairHiggs:\n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        n_higgs = (data.node_type == 1).sum()\n",
    "        n_dihiggs = n_higgs*(n_higgs-1)//2\n",
    "\n",
    "        dihiggs_features = torch.zeros(n_dihiggs, data.num_node_features)\n",
    "\n",
    "        dijets = torch.where(data.node_type == 1)[0]\n",
    "        dihiggs_i = torch.repeat_interleave(dijets, n_higgs)\n",
    "        dihiggs_j = torch.repeat_interleave(dijets[None], n_higgs, dim=0).reshape(-1)\n",
    "        uptri_mask = dihiggs_i < dihiggs_j\n",
    "\n",
    "        dihiggs_i = dihiggs_i[uptri_mask]\n",
    "        dihiggs_j = dihiggs_j[uptri_mask]\n",
    "\n",
    "        dihiggs_1 = (data.node_id[dihiggs_i] == 1) & (data.node_id[dihiggs_j] == 2)\n",
    "        dihiggs_2 = (data.node_id[dihiggs_i] == 3) & (data.node_id[dihiggs_j] == 4)\n",
    "\n",
    "        data.node_type = torch.cat([data.node_type, torch.full_like(dihiggs_i, 2)]).long()\n",
    "        data.node_id = torch.cat([data.node_id, 1*dihiggs_1 + 2*dihiggs_2]).long()\n",
    "\n",
    "        data.x = torch.cat([data.x, dihiggs_features])\n",
    "        data.y = torch.cat([data.y, 1*(dihiggs_1 | dihiggs_2)]).long()\n",
    "\n",
    "        dihiggs_idx = torch.where(data.node_type == 2)[0]\n",
    "        data.edge_index = torch.stack([torch.cat([data.edge_index[0], dihiggs_i,   dihiggs_idx, dihiggs_j,   dihiggs_idx]), \n",
    "                                    torch.cat([data.edge_index[1], dihiggs_idx, dihiggs_j,   dihiggs_idx, dihiggs_i])])\n",
    "\n",
    "        data.edge_attr = torch.ones_like(data.edge_index[0]).reshape(-1,1)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c848286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairYs:\n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        n_ys = (data.node_type == 2).sum()\n",
    "        n_diys = n_ys*(n_ys-1)//2\n",
    "\n",
    "        diys_features = torch.zeros(n_diys, data.num_node_features)\n",
    "\n",
    "        dihiggs = torch.where(data.node_type == 2)[0]\n",
    "        diys_i = torch.repeat_interleave(dihiggs, n_ys)\n",
    "        diys_j = torch.repeat_interleave(dihiggs[None], n_ys, dim=0).reshape(-1)\n",
    "        uptri_mask = diys_i < diys_j\n",
    "\n",
    "        diys_i = diys_i[uptri_mask]\n",
    "        diys_j = diys_j[uptri_mask]\n",
    "\n",
    "        diys_1 = (data.node_id[diys_i] == 1) & (data.node_id[diys_j] == 2)\n",
    "\n",
    "        data.node_type = torch.cat([data.node_type, torch.full_like(diys_i, 3)]).long()\n",
    "        data.node_id = torch.cat([data.node_id, 1*diys_1]).long()\n",
    "\n",
    "\n",
    "        data.x = torch.cat([data.x, diys_features])\n",
    "        data.y = torch.cat([data.y, 1*(diys_1)]).long()\n",
    "\n",
    "        diys_idx = torch.where(data.node_type == 3)[0]\n",
    "        data.edge_index = torch.stack([torch.cat([data.edge_index[0], diys_i,   diys_idx, diys_j,   diys_idx]), \n",
    "                                       torch.cat([data.edge_index[1], diys_idx, diys_j,   diys_idx, diys_i])])\n",
    "\n",
    "        data.edge_attr = torch.ones_like(data.edge_index[0]).reshape(-1,1)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902ea6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassWeight:\n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        true_mask = data.y == 1\n",
    "        true_weight = (data.num_nodes - true_mask.sum())/data.num_nodes\n",
    "        fake_weight = 1 - true_weight\n",
    "        data.weight = torch.where(true_mask, true_weight, fake_weight)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a24c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, DenseDataLoader\n",
    "\n",
    "def load_dataset(fn='data/MX_1200_MY_500-training', template=None, shuffle=False):\n",
    "    dataset = gnn.Dataset(fn,transform=template.transform)\n",
    "    training, testing = gnn.train_test_split(dataset[:3000], 0.33)\n",
    "    training, validation = gnn.train_test_split(training, 0.5)\n",
    "\n",
    "    batch_size = 50\n",
    "    trainloader = DataLoader(training, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "    validloader = DataLoader(validation, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "    testloader = DataLoader(testing, batch_size=batch_size, shuffle=shuffle, num_workers=8)\n",
    "\n",
    "    return trainloader, validloader, testloader\n",
    "\n",
    "template = gnn.Dataset('data/template',make_template=True, transform=gnn.Transform(PairJets(), NodeClassWeight()))\n",
    "trainloader, validloader, testloader = load_dataset(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "730c3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoldenModule(Module):\n",
    "    def __init__(self, n_in_node=5, n_in_edge=4, layers=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = gnn.layers.GCNConvMSG(n_in_node=n_in_node, n_in_edge=n_in_edge, n_out=layers)\n",
    "        self.relu1 = gnn.layers.GCNRelu()\n",
    "        self.norm1 = gnn.layers.GCNNormalize()\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj, edge_attr: Tensor) -> Tensor:\n",
    "        x, edge_attr = self.conv1(x, edge_index, edge_attr)\n",
    "        x, edge_attr = self.relu1(x, edge_index, edge_attr)\n",
    "        x, edge_attr = self.norm1(x, edge_index, edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff7bd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeClassLinear(Module):\n",
    "    def __init__(self, n_in, n_out, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features, self.out_features = n_in, n_out\n",
    "        self.n_classes = n_classes\n",
    "        self.linear = [ torch.nn.Linear(n_in, n_out) for _ in range(n_classes) ]            \n",
    "    def __call__(self, x : Tensor, classes : Tensor) -> Tensor:\n",
    "        x = [ linear(x[classes == i]) for i, linear in enumerate(self.linear) ]\n",
    "        return torch.cat(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcab2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from torch.nn.functional import nll_loss, log_softmax, binary_cross_entropy\n",
    "from torchmetrics.functional import accuracy, auroc\n",
    "\n",
    "class Model(LightningModule):\n",
    "    def __init__(self,n_in_node=5, n_in_edge=1):\n",
    "        super().__init__()\n",
    "        self.norm = gnn.layers.GCNNormalize()\n",
    "\n",
    "        self.golden1 = GoldenModule(n_in_node=n_in_node, n_in_edge=n_in_edge, layers=32)\n",
    "        self.linear1 = NodeClassLinear(32, 64, 2)\n",
    "        self.golden2 = GoldenModule(n_in_node=64, n_in_edge=32, layers=128)\n",
    "        self.linear2 = NodeClassLinear( 64, 32, 2)\n",
    "\n",
    "        self.linear3 = NodeClassLinear( 32,  1, 2)\n",
    "\n",
    "    def forward(self, data : Data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x, edge_attr = self.golden1(x, edge_index, edge_attr)\n",
    "        x = self.linear1(x, data.node_type)\n",
    "\n",
    "        x, edge_attr = self.golden2(x, edge_index, edge_attr)\n",
    "        x = self.linear2(x, data.node_type)\n",
    "\n",
    "        x = self.linear3(x, data.node_type)\n",
    "\n",
    "        return softmax(x, dim=-1)[:,1]\n",
    "\n",
    "    def step(self, batch, batch_idx, tag):\n",
    "        o = self(batch)\n",
    "        y = batch.y\n",
    "        loss = binary_cross_entropy(o, y.float(), batch.weight)\n",
    "        node_auroc = auroc(o, y)\n",
    "        self.log(f'{tag}/node_auroc',node_auroc)\n",
    "        self.log(f'{tag}/loss',loss)\n",
    "        return loss\n",
    "    def training_step(self, batch, batch_idx): return self.step(batch ,batch_idx, 'train')\n",
    "    def validation_step(self, batch, batch_idx): return self.step(batch ,batch_idx, 'valid')\n",
    "    def test_step(self, batch, batch_idx):  return self.step(batch ,batch_idx, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "406a80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trainloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "318a2254",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d896974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type            | Params\n",
      "--------------------------------------------\n",
      "0 | norm    | GCNNormalize    | 0     \n",
      "1 | golden1 | GoldenModule    | 384   \n",
      "2 | linear1 | NodeClassLinear | 0     \n",
      "3 | golden2 | GoldenModule    | 20.6 K\n",
      "4 | linear2 | NodeClassLinear | 0     \n",
      "5 | linear3 | NodeClassLinear | 0     \n",
      "--------------------------------------------\n",
      "21.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.0 K    Total params\n",
      "0.084     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking arugment for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000028vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000028vscode-remote?line=2'>3</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000028vscode-remote?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, trainloader, validloader)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=734'>735</a>\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=735'>736</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=736'>737</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=737'>738</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=738'>739</a>\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=739'>740</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=740'>741</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=741'>742</a>\u001b[0m )\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=674'>675</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=675'>676</a>\u001b[0m \u001b[39mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=676'>677</a>\u001b[0m \u001b[39mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=681'>682</a>\u001b[0m \u001b[39m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=682'>683</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=684'>685</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=685'>686</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=686'>687</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=774'>775</a>\u001b[0m \u001b[39m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=775'>776</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=776'>777</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=778'>779</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=779'>780</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1199\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1195'>1196</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1197'>1198</a>\u001b[0m \u001b[39m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1198'>1199</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch()\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1200'>1201</a>\u001b[0m \u001b[39m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1201'>1202</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_dispatch()\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1279\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1276'>1277</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mstart_predicting(\u001b[39mself\u001b[39m)\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1277'>1278</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1278'>1279</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mstart_training(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:202\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=199'>200</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart_training\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m\"\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=200'>201</a>\u001b[0m     \u001b[39m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=201'>202</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun_stage()\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1289\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1286'>1287</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1287'>1288</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1288'>1289</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1311\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1307'>1308</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_global_zero \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1308'>1309</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar_callback\u001b[39m.\u001b[39mdisable()\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1310'>1311</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module)\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1312'>1313</a>\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1313'>1314</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1375\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1372'>1373</a>\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1373'>1374</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1374'>1375</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1376'>1377</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1378'>1379</a>\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:110\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=104'>105</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_fetcher \u001b[39m=\u001b[39m dataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mget_profiled_dataloader(\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=105'>106</a>\u001b[0m     dataloader, dataloader_idx\u001b[39m=\u001b[39mdataloader_idx\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=106'>107</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=107'>108</a>\u001b[0m dl_max_batches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_batches[dataloader_idx]\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=109'>110</a>\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(dataloader, dataloader_idx, dl_max_batches, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_dataloaders)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=111'>112</a>\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=112'>113</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:122\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=119'>120</a>\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=120'>121</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mevaluation_step_and_end\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=121'>122</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=122'>123</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=124'>125</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:217\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=214'>215</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=215'>216</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=216'>217</a>\u001b[0m         output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mvalidation_step(step_kwargs)\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=218'>219</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py:236\u001b[0m, in \u001b[0;36mAccelerator.validation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py?line=230'>231</a>\u001b[0m \u001b[39m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py?line=231'>232</a>\u001b[0m \n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py?line=232'>233</a>\u001b[0m \u001b[39mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py?line=233'>234</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py?line=234'>235</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py?line=235'>236</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:219\u001b[0m, in \u001b[0;36mTrainingTypePlugin.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=217'>218</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=218'>219</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb Cell 10'\u001b[0m in \u001b[0;36mModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(batch ,batch_idx, \u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb Cell 10'\u001b[0m in \u001b[0;36mModel.step\u001b[0;34m(self, batch, batch_idx, tag)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx, tag):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=29'>30</a>\u001b[0m     o \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=30'>31</a>\u001b[0m     y \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39my\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=31'>32</a>\u001b[0m     loss \u001b[39m=\u001b[39m binary_cross_entropy(o, y\u001b[39m.\u001b[39mfloat(), batch\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb Cell 10'\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=17'>18</a>\u001b[0m x, edge_index, edge_attr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39medge_attr\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=18'>19</a>\u001b[0m x, edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgolden1(x, edge_index, edge_attr)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=19'>20</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1(x, data\u001b[39m.\u001b[39;49mnode_type)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=21'>22</a>\u001b[0m x, edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgolden2(x, edge_index, edge_attr)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000005vscode-remote?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(x, data\u001b[39m.\u001b[39mnode_type)\n",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb Cell 9'\u001b[0m in \u001b[0;36mNodeClassLinear.__call__\u001b[0;34m(self, x, classes)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000037vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x : Tensor, classes : Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000037vscode-remote?line=8'>9</a>\u001b[0m     x \u001b[39m=\u001b[39m [ linear(x[classes \u001b[39m==\u001b[39m i]) \u001b[39mfor\u001b[39;00m i, linear \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear) ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000037vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(x)\n",
      "\u001b[1;32m/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb Cell 9'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000037vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x : Tensor, classes : Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000037vscode-remote?line=8'>9</a>\u001b[0m     x \u001b[39m=\u001b[39m [ linear(x[classes \u001b[39m==\u001b[39;49m i]) \u001b[39mfor\u001b[39;00m i, linear \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear) ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfnalgpu1/uscms_data/d3/ekoenig/8BAnalysis/studies/sixbStudies/jupyter/eightb/pairing_methods/graph_net/gnn_benchmark.ipynb#ch0000037vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(x)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=94'>95</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=95'>96</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/functional.py?line=1844'>1845</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[1;32m   <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/functional.py?line=1845'>1846</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> <a href='file:///uscms/home/ekoenig/nobackup/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/functional.py?line=1846'>1847</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking arugment for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(gpus=1, max_epochs=10)\n",
    "trainer.fit(model, trainloader, validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66ee351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 20/20 [00:01<00:00, 18.97it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/loss': 0.21773627400398254, 'test/node_auroc': 0.5057910680770874}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|| 20/20 [00:01<00:00, 13.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/node_auroc': 0.5057910680770874, 'test/loss': 0.21773627400398254}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9614573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2043, 0.2238, 0.2403, 0.2031, 0.1956, 0.2434, 0.2203, 0.2313, 0.1749,\n",
       "        0.1914, 0.1813, 0.1733, 0.1978, 0.1908, 0.1956, 0.1811, 0.1759, 0.1822,\n",
       "        0.1890, 0.1953, 0.1979, 0.1713, 0.1875, 0.1917, 0.1998, 0.2033, 0.1700,\n",
       "        0.1926, 0.1887, 0.1942, 0.1873, 0.1849, 0.1889, 0.2039, 0.2081, 0.1938],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(testloader.dataset[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dc50badf6bcf34ee37feb4ddab24eb1b71716d96fc6cae89d10c22f5e3462c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
